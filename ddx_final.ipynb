{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0hYelLS4K7V"
      },
      "source": [
        "<h1> Medical Differential Diagnosis with Mistral 7B RAG vs. BioMistral 7B </h1>\n",
        "<h3> Comparing RAG-Enhanced General Models vs Domain-Specific Models </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.29)\n",
            "Requirement already satisfied: transformers in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.55.4)\n",
            "Requirement already satisfied: openpyxl in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.5)\n",
            "Requirement already satisfied: sentence_transformers in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.1.0)\n",
            "Requirement already satisfied: faiss-cpu in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.0)\n",
            "Requirement already satisfied: pypdf in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (6.0.0)\n",
            "Requirement already satisfied: hf_xet in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.9)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.3.75)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.4.19)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (2.1.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.7.34)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (2.6.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\ignasius.dwi\\appdata\\roaming\\python\\python310\\site-packages (from sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.2.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: networkx in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ignasius.dwi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ignasius.dwi\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ignasius.dwi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community transformers openpyxl sentence_transformers faiss-cpu pypdf hf_xet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3> Configuration </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import glob\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For RAG purpose\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Pipeline - using smaller alternatives for portfolio demo\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM, \n",
        "    pipeline, BitsAndBytesConfig\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wPfBDSg4QUEO"
      },
      "outputs": [],
      "source": [
        "# Configuration - adjustable\n",
        "\n",
        "class Config:\n",
        "    # Use smaller models for portfolio demo that are able to run locally\n",
        "    RAG_MODEL = \"microsoft/DialoGPT-medium\"  # Naive LLMs, dummies\n",
        "    BIO_MODEL = \"dmis-lab/biobert-base-cased-v1.1\"  # Bio domain LLMs, dummies\n",
        "    \n",
        "    # For actual implementation, these would be:\n",
        "    # RAG_MODEL = \"mistralai/Mistral-7B-Instruct-v0.1\" \n",
        "    # BIO_MODEL = \"BioMistral/BioMistral-7B\"\n",
        "    # In production, use API from HuggingFace: token required\n",
        "    \n",
        "    EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # dummies\n",
        "    \n",
        "    PROMPT = \"What are the top 10 most likely differential diagnoses? List them in order of likelihood:\"\n",
        "\n",
        "    CURRENT_DIR = Path.cwd()\n",
        "    DATA_DIR = Path(\"./data\")\n",
        "    CASES_FILE = DATA_DIR / \"sample_cases.xlsx\"\n",
        "    VECTOR_DB_DIR = DATA_DIR / \"vector_db\"\n",
        "    RESULTS_DIR = DATA_DIR / \"results\"\n",
        "    \n",
        "    # PDF processing settings, adjustable depends on the PDF characteristics\n",
        "    CHUNK_SIZE = 1000\n",
        "    CHUNK_OVERLAP = 200\n",
        "\n",
        "    MAX_LENGTH = 1024 # Setting context's length\n",
        "    MAX_NEW_TOKENS = 200 # Control output length\n",
        "    BATCH_SIZE = 4\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m8w2TGRlyoyi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded. Current directory: d:\\Data Gita\\Documents\\AI for Health - Stockholm University\\8. NLP\\Project\\ddx\n",
            "Data directory: data\n"
          ]
        }
      ],
      "source": [
        "# Create directories\n",
        "for dir_path in [config.DATA_DIR, config.VECTOR_DB_DIR, config.RESULTS_DIR]:\n",
        "    dir_path.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Configuration loaded. Current directory: {config.CURRENT_DIR}\")\n",
        "print(f\"Data directory: {config.DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3> Define RAG Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MedicalRAGSystem:\n",
        "    \"\"\"RAG system for medical differential diagnosis using PDF documents\"\"\"\n",
        "    \n",
        "    def __init__(self, config): # Initialization\n",
        "        self.config = config\n",
        "        self.embeddings = None\n",
        "        self.vector_store = None\n",
        "        self.documents = []\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=config.CHUNK_SIZE,\n",
        "            chunk_overlap=config.CHUNK_OVERLAP,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
        "        )\n",
        "        \n",
        "    def load_embeddings(self):\n",
        "        \"\"\"Load embedding model\"\"\"\n",
        "        print(\"Loading embedding model...\")\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=self.config.EMBEDDING_MODEL,\n",
        "            model_kwargs={'device': 'cpu'}  # Use CPU for compatibility, real app use GPU\n",
        "        )\n",
        "        print(\"Embeddings loaded successfully!\")\n",
        "        \n",
        "    def find_pdf_files(self):\n",
        "        \"\"\"Find all PDF files in the current directory, assuming all PDF files are RAG resources\"\"\"\n",
        "        pdf_files = list(self.config.CURRENT_DIR.glob(\"*.pdf\"))\n",
        "        if not pdf_files:\n",
        "            print(f\"No PDF files found in {self.config.CURRENT_DIR}\")\n",
        "            print(\"Please place your medical PDF documents in the same folder as this script.\")\n",
        "        else:\n",
        "            print(f\"Found {len(pdf_files)} PDF files:\")\n",
        "            for pdf_file in pdf_files:\n",
        "                print(f\"  - {pdf_file.name}\")\n",
        "        return pdf_files\n",
        "    \n",
        "    def load_pdf_documents(self):\n",
        "        \"\"\"Load and process PDF documents from the current directory\"\"\"\n",
        "        pdf_files = self.find_pdf_files()\n",
        "        \n",
        "        if not pdf_files:\n",
        "            print(\"WARNING: No PDF files found. Creating fallback sample documents...\")\n",
        "            self.create_sample_medical_knowledge()\n",
        "            return\n",
        "        \n",
        "        print(\"Loading PDF documents...\")\n",
        "        all_documents = []\n",
        "        \n",
        "        for pdf_file in pdf_files:\n",
        "            try:\n",
        "                print(f\"Processing: {pdf_file.name}\")\n",
        "                \n",
        "                # Load PDF\n",
        "                loader = PyPDFLoader(str(pdf_file))\n",
        "                pages = loader.load()\n",
        "                \n",
        "                # Split into chunks\n",
        "                chunks = self.text_splitter.split_documents(pages)\n",
        "                \n",
        "                # Add source metadata\n",
        "                for chunk in chunks:\n",
        "                    chunk.metadata.update({\n",
        "                        'source_file': pdf_file.name,\n",
        "                        'file_path': str(pdf_file),\n",
        "                        'total_pages': len(pages)\n",
        "                    })\n",
        "                \n",
        "                all_documents.extend(chunks)\n",
        "                print(f\"Loaded {len(chunks)} chunks from {pdf_file.name}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {pdf_file.name}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        if all_documents:\n",
        "            self.documents = all_documents\n",
        "            print(f\"Successfully loaded {len(all_documents)} document chunks from {len(pdf_files)} PDF files\")\n",
        "        else:\n",
        "            print(\"ERROR: Failed to load any PDF documents. Creating fallback documents...\") # Fail-safe mechanism\n",
        "            self.create_sample_medical_knowledge()\n",
        "\n",
        "        \n",
        "    def create_sample_medical_knowledge(self): # For demonstration purposes\n",
        "        \"\"\"Mock-up Medical Documents: as fallback if no PDFs found\n",
        "        This is used for the fail-safe mechanism. Other mechanism is also possible, for example: looking at online references\"\"\"\n",
        "        \n",
        "        print(\"Creating fallback sample medical documents...\")\n",
        "        sample_docs = [\n",
        "            {\n",
        "                \"title\": \"Acute Myocardial Infarction\",\n",
        "                \"content\": \"\"\"Acute myocardial infarction (AMI) is characterized by chest pain, often radiating to the left arm, jaw, or back. Key features include ST elevation on ECG, elevated cardiac enzymes (troponin, CK-MB), and typical presentation during or after physical exertion. Risk factors include hypertension, diabetes, smoking, and family history. Immediate treatment includes aspirin, nitroglycerin, and emergency catheterization.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"title\": \"Bacterial Meningitis\",\n",
        "                \"content\": \"\"\"Bacterial meningitis presents with classic triad of fever, headache, and neck stiffness. Positive Kernig's and Brudzinski's signs are pathognomonic. CSF analysis shows elevated WBC with neutrophil predominance, low glucose (<40% of serum), and elevated protein. Common organisms include Streptococcus pneumoniae, Neisseria meningitidis, and Haemophilus influenzae. Emergency treatment with broad-spectrum antibiotics is crucial.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"title\": \"Diabetic Ketoacidosis\",\n",
        "                \"content\": \"\"\"DKA is characterized by hyperglycemia (>250 mg/dL), ketosis, and metabolic acidosis. Classic symptoms include polyuria, polydipsia, weight loss, and fruity breath odor. Laboratory findings show positive urine ketones, low bicarbonate, and elevated anion gap. Treatment involves IV fluids, insulin therapy, and electrolyte correction. Common precipitants include infection, medication noncompliance, and new-onset diabetes.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"title\": \"Pregnancy Complications\",\n",
        "                \"content\": \"\"\"Abortion complications in pregnancy include threatened, inevitable, incomplete, and complete abortion. Inevitable abortion presents with open cervix and cramping pain. Incomplete abortion shows retained tissue with continued bleeding. Ultrasound helps differentiate between types. Placental abruption presents with severe abdominal pain and may show concealed hemorrhage.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"title\": \"Pediatric Infections\",\n",
        "                \"content\": \"\"\"Streptococcal pharyngitis in children presents with fever, sore throat, tonsillar exudate, and cervical lymphadenopathy. Centor criteria help distinguish from viral causes. Rapid strep test or throat culture confirms diagnosis. Treatment includes penicillin or amoxicillin. Complications may include rheumatic fever if untreated.\"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        documents = []\n",
        "        for doc in sample_docs:\n",
        "            documents.append(Document(\n",
        "                page_content=doc[\"content\"],\n",
        "                metadata={\"title\": doc[\"title\"],\n",
        "                    \"source_file\": \"fallback_sample\",\n",
        "                    \"file_path\": \"internal_sample\"}\n",
        "            ))\n",
        "        \n",
        "        self.documents = documents\n",
        "        print(f\"Created {len(documents)} fallback medical documents\")\n",
        "        \n",
        "    def build_vector_store(self):\n",
        "        \"\"\"Build FAISS vector store from documents\"\"\"\n",
        "        if not self.embeddings:\n",
        "            self.load_embeddings()\n",
        "            \n",
        "        if not self.documents:\n",
        "            self.load_pdf_documents()\n",
        "        \n",
        "        print(\"Building vector store...\")\n",
        "        self.vector_store = FAISS.from_documents(\n",
        "            self.documents,\n",
        "            self.embeddings\n",
        "        )\n",
        "        \n",
        "        # Save vector store\n",
        "        self.vector_store.save_local(str(self.config.VECTOR_DB_DIR))\n",
        "        print(f\"Vector store saved to {self.config.VECTOR_DB_DIR}\")\n",
        "        \n",
        "        # Save document metadata for reference\n",
        "        metadata_file = self.config.DATA_DIR / \"document_metadata.json\"\n",
        "        metadata = []\n",
        "        for doc in self.documents:\n",
        "            metadata.append({\n",
        "                \"content_preview\": doc.page_content[:200] + \"...\",\n",
        "                \"metadata\": doc.metadata\n",
        "            })\n",
        "        \n",
        "        with open(metadata_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Document metadata saved to {metadata_file}\")\n",
        "\n",
        "    def retrieve_context(self, query, k=3, max_context_length=2000):\n",
        "        \"\"\"Retrieve relevant context for a query\"\"\"\n",
        "        if not self.vector_store:\n",
        "            print(\"Loading vector store...\")\n",
        "            self.load_embeddings()\n",
        "            try:\n",
        "                self.vector_store = FAISS.load_local(\n",
        "                    str(self.config.VECTOR_DB_DIR), \n",
        "                    self.embeddings\n",
        "            )\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading vector store: {e}\")\n",
        "                print(\"Rebuilding vector store...\")\n",
        "                self.build_vector_store()\n",
        "        \n",
        "\n",
        "        docs = self.vector_store.similarity_search(query, k=k)\n",
        "        sources = [doc.metadata.get(\"source_file\", \"Unknown\") for doc in docs]\n",
        "        \n",
        "        # Truncate context to prevent token limit issues\n",
        "        context_parts = []\n",
        "        current_length = 0\n",
        "        \n",
        "        for doc in docs:\n",
        "            content = doc.page_content\n",
        "            if current_length + len(content) <= max_context_length:\n",
        "                context_parts.append(content)\n",
        "                current_length += len(content)\n",
        "            else:\n",
        "                # Add partial content if there's room\n",
        "                remaining = max_context_length - current_length\n",
        "                if remaining > 100:  # Only add if meaningful amount remains\n",
        "                    context_parts.append(content[:remaining] + \"...\")\n",
        "                break\n",
        "        \n",
        "        context = \"\\n\\n\".join(context_parts)\n",
        "        return context, sources\n",
        "\n",
        "    \n",
        "    def get_document_statistics(self):\n",
        "        \"\"\"Get statistics about loaded documents\"\"\"\n",
        "        if not self.documents:\n",
        "            return {\"error\": \"No documents loaded\"}\n",
        "        \n",
        "        stats = {\n",
        "            \"total_chunks\": len(self.documents),\n",
        "            \"source_files\": {},\n",
        "            \"average_chunk_length\": np.mean([len(doc.page_content) for doc in self.documents]),\n",
        "            \"total_content_length\": sum([len(doc.page_content) for doc in self.documents])\n",
        "        }\n",
        "        \n",
        "        # Count chunks per source file\n",
        "        for doc in self.documents:\n",
        "            source = doc.metadata.get(\"source_file\", \"Unknown\")\n",
        "            if source not in stats[\"source_files\"]:\n",
        "                stats[\"source_files\"][source] = 0\n",
        "            stats[\"source_files\"][source] += 1\n",
        "        \n",
        "        return stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "INITIALIZING RAG SYSTEM\n",
            "============================================================\n",
            "Loading embedding model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ignasius.dwi\\AppData\\Local\\Temp\\ipykernel_12272\\2457445398.py:18: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  self.embeddings = HuggingFaceEmbeddings(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings loaded successfully!\n",
            "No PDF files found in d:\\Data Gita\\Documents\\AI for Health - Stockholm University\\8. NLP\\Project\\ddx\n",
            "Please place your medical PDF documents in the same folder as this script.\n",
            "WARNING: No PDF files found. Creating fallback sample documents...\n",
            "Creating fallback sample medical documents...\n",
            "Created 5 fallback medical documents\n",
            "Building vector store...\n",
            "Vector store saved to data\\vector_db\n",
            "Document metadata saved to data\\document_metadata.json\n"
          ]
        }
      ],
      "source": [
        "# Initialize RAG system\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"INITIALIZING RAG SYSTEM\")\n",
        "print(\"=\" * 60)\n",
        "rag_system = MedicalRAGSystem(config)\n",
        "rag_system.build_vector_store()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "DOCUMENT STATISTICS\n",
            "============================================================\n",
            "Total document chunks: 5\n",
            "Average chunk length: 393 characters\n",
            "Total content length: 1,966 characters\n",
            "Source files:\n",
            "  - fallback_sample: 5 chunks\n"
          ]
        }
      ],
      "source": [
        "# Display document statistics\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DOCUMENT STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "stats = rag_system.get_document_statistics()\n",
        "if \"error\" not in stats:\n",
        "    print(f\"Total document chunks: {stats['total_chunks']}\")\n",
        "    print(f\"Average chunk length: {stats['average_chunk_length']:.0f} characters\")\n",
        "    print(f\"Total content length: {stats['total_content_length']:,} characters\")\n",
        "    print(f\"Source files:\")\n",
        "    for source, count in stats['source_files'].items():\n",
        "        print(f\"  - {source}: {count} chunks\")\n",
        "else:\n",
        "    print(stats[\"error\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TESTING RAG RETRIEVAL\n",
            "============================================================\n",
            "Query: 'patient with chest pain and ST elevation'\n",
            "Sources: ['fallback_sample', 'fallback_sample', 'fallback_sample']\n",
            "Context preview: Acute myocardial infarction (AMI) is characterized by chest pain, often radiating to the left arm, jaw, or back. Key features include ST elevation on ECG, elevated cardiac enzymes (troponin, CK-MB), and typical presentation during or after physical exertion. Risk factors include hypertension, diabet...\n"
          ]
        }
      ],
      "source": [
        "# Test RAG retrieval, see if it's working\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TESTING RAG RETRIEVAL\")\n",
        "print(\"=\" * 60)\n",
        "test_query = \"patient with chest pain and ST elevation\"\n",
        "context, sources = rag_system.retrieve_context(test_query)\n",
        "print(f\"Query: '{test_query}'\")\n",
        "print(f\"Sources: {sources}\")\n",
        "print(f\"Context preview: {context[:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Load the model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MedicalDiagnosisModels:\n",
        "    \"\"\"Wrapper for both RAG-enhanced and Bio-specialized models\"\"\"\n",
        "    \n",
        "    def __init__(self, config, rag_system):\n",
        "        self.config = config\n",
        "        self.rag_system = rag_system\n",
        "        self.rag_pipeline = None\n",
        "        self.bio_pipeline = None\n",
        "        \n",
        "    def load_rag_model(self):\n",
        "        \"\"\"Load RAG-enhanced general model\"\"\"\n",
        "        print(f\"Loading RAG model: {self.config.RAG_MODEL}\")\n",
        "        \n",
        "        # For portfolio demo - using smaller model\n",
        "        # In production, this would be Mistral-7B with quantization\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.config.RAG_MODEL, padding_side='left')\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "                \n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.config.RAG_MODEL,\n",
        "                torch_dtype=torch.float32,  # CPU compatible, adjust for GPU implementation\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "            \n",
        "            self.rag_pipeline = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                max_new_tokens=self.config.MAX_NEW_TOKENS,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                truncation=True,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "            print(\"RAG model loaded successfully!\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading RAG model: {e}\")\n",
        "            print(\"Using mock RAG model for demonstration...\")\n",
        "            self.rag_pipeline = self._create_mock_rag_pipeline()\n",
        "    \n",
        "    def load_bio_model(self):\n",
        "        \"\"\"Load bio-specialized model\"\"\"\n",
        "        print(f\"Loading Bio model: {self.config.BIO_MODEL}\")\n",
        "        \n",
        "        # For portfolio demo - using mock since BioMistral-7B is too large\n",
        "        print(\"Using mock Bio model for demonstration...\")\n",
        "        self.bio_pipeline = self._create_mock_bio_pipeline()\n",
        "    \n",
        "    def _create_mock_rag_pipeline(self):\n",
        "        \"\"\"For demo purposes, this is safe-mechanism for fallback mock function. Another option is to show the error code and stop the process.\n",
        "        This will activate if model loading fails, API limits are hit, or hardware constraints.\"\"\"\n",
        "        def mock_rag(prompt, **kwargs):\n",
        "            # Simulate RAG-enhanced responses based on retrieved context\n",
        "            if \"chest pain\" in prompt.lower() and \"st elevation\" in prompt.lower():\n",
        "                return [{\"generated_text\": prompt + \"\\n\\nBased on the retrieved medical literature, the top 10 differential diagnoses are:\\n1. Acute ST-elevation myocardial infarction (STEMI)\\n2. Non-ST elevation myocardial infarction (NSTEMI)\\n3. Unstable angina pectoris\\n4. Acute pericarditis\\n5. Aortic dissection\\n6. Pulmonary embolism\\n7. Pneumothorax\\n8. Esophageal rupture\\n9. Gastroesophageal reflux disease\\n10. Musculoskeletal chest pain\"}]\n",
        "            elif \"fever\" in prompt.lower() and \"neck stiffness\" in prompt.lower():\n",
        "                return [{\"generated_text\": prompt + \"\\n\\nBased on retrieved medical knowledge, the differential diagnoses include:\\n1. Bacterial meningitis\\n2. Viral meningitis\\n3. Subarachnoid hemorrhage\\n4. Brain abscess\\n5. Encephalitis\\n6. Migraine headache\\n7. Tension headache\\n8. Sinusitis\\n9. Temporal arteritis\\n10. Drug-induced meningitis\"}]\n",
        "            else:\n",
        "                return [{\"generated_text\": prompt + \"\\n\\n[RAG Model Response - Context-enhanced diagnosis based on retrieved medical literature]\"}]\n",
        "        return mock_rag\n",
        "    \n",
        "    def _create_mock_bio_pipeline(self):\n",
        "        \"\"\"For demo purposes, this is safe-mechanism for fallback mock function. Another option is to show the error code and stop the process.\n",
        "        This will activate if model loading fails, API limits are hit, or hardware constraints.\"\"\"\n",
        "        def mock_bio(prompt, **kwargs):\n",
        "            # Simulate bio-specialized responses\n",
        "            if \"chest pain\" in prompt.lower():\n",
        "                return [{\"generated_text\": prompt + \"\\n\\nBio-specialized analysis:\\n1. Acute myocardial infarction\\n2. Unstable angina\\n3. Aortic dissection\\n4. Pulmonary embolism\\n5. Pneumothorax\\n6. Pericarditis\\n7. Esophageal disorders\\n8. Musculoskeletal pain\\n9. Anxiety disorder\\n10. Gastric reflux\"}]\n",
        "            elif \"fever\" in prompt.lower() and \"headache\" in prompt.lower():\n",
        "                return [{\"generated_text\": prompt + \"\\n\\nBio-specialized differential:\\n1. Bacterial meningitis\\n2. Viral meningitis\\n3. Encephalitis\\n4. Subarachnoid hemorrhage\\n5. Brain tumor\\n6. Migraine\\n7. Cluster headache\\n8. Sinusitis\\n9. Hypertensive emergency\\n10. Carbon monoxide poisoning\"}]\n",
        "            else:\n",
        "                return [{\"generated_text\": prompt + \"\\n\\n[Bio-Specialized Model Response - Domain-specific medical analysis]\"}]\n",
        "        return mock_bio\n",
        "    \n",
        "    def generate_rag_diagnosis(self, case_description):\n",
        "        \"\"\"Generate diagnosis using RAG-enhanced model\"\"\"\n",
        "        if not self.rag_pipeline:\n",
        "            self.load_rag_model()\n",
        "        \n",
        "        # Retrieve relevant context\n",
        "        context, sources = self.rag_system.retrieve_context(case_description, max_context_length=1500)\n",
        "        \n",
        "        # Create RAG prompt\n",
        "        prompt = f\"\"\"Context: {context[:1500]}\n",
        "\n",
        "Case: {case_description[:500]}\n",
        "\n",
        "{self.config.PROMPT}\"\"\"\n",
        "        \n",
        "        try:\n",
        "            # Check prompt length\n",
        "            tokenizer = self.rag_pipeline.tokenizer\n",
        "            tokens = tokenizer.encode(prompt)\n",
        "            \n",
        "            if len(tokens) > 800:  # Leave room for generation\n",
        "                print(f\"Warning: Prompt too long ({len(tokens)} tokens), truncating...\")\n",
        "                # Truncate context more aggressively\n",
        "                context = context[:800]\n",
        "\n",
        "                #Shorter the prompt so it can fit the context window\n",
        "                prompt = f\"\"\"Medical context: {context}\n",
        "\n",
        "Case: {case_description[:300]} \n",
        "\n",
        "{self.config.PROMPT}:\"\"\"\n",
        "            \n",
        "            response = self.rag_pipeline(\n",
        "                prompt, \n",
        "                max_new_tokens=self.config.MAX_NEW_TOKENS,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                truncation=True\n",
        "            )\n",
        "            \n",
        "            diagnosis = response[0][\"generated_text\"][len(prompt):].strip()\n",
        "            return {\n",
        "                \"diagnosis\": diagnosis,\n",
        "                \"sources\": sources,\n",
        "                \"method\": \"RAG-Enhanced\",\n",
        "                \"prompt_tokens\": len(tokens) if 'tokens' in locals() else 0\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"RAG generation error: {e}\")\n",
        "            return {\n",
        "                \"diagnosis\": f\"Error: {str(e)[:100]}...\",\n",
        "                \"sources\": sources,\n",
        "                \"method\": \"RAG-Enhanced\",\n",
        "                \"prompt_tokens\": 0\n",
        "            }\n",
        "        \n",
        "    def generate_bio_diagnosis(self, case_description):\n",
        "        \"\"\"Generate diagnosis using bio-specialized model\"\"\"\n",
        "        if not self.bio_pipeline:\n",
        "            self.load_bio_model()\n",
        "        \n",
        "        truncated_case = case_description[:400] # Prevent token issues\n",
        "        prompt = f\"\"\"Case: {truncated_case}\n",
        "\n",
        "{self.config.PROMPT}\"\"\"\n",
        "        \n",
        "        try:\n",
        "            response = self.bio_pipeline(\n",
        "                prompt, \n",
        "                max_new_tokens=self.config.MAX_NEW_TOKENS,\n",
        "                truncation=True\n",
        "            )\n",
        "            diagnosis = response[0][\"generated_text\"][len(prompt):].strip()\n",
        "            return {\n",
        "                \"diagnosis\": diagnosis,\n",
        "                \"sources\": [\"Bio-specialized training data\"],\n",
        "                \"method\": \"Bio-Specialized\"\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"diagnosis\": f\"Error: {str(e)[:100]}...\",\n",
        "                \"sources\": [\"Error\"],\n",
        "                \"method\": \"Bio-Specialized\"\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3> Prepare the Dataset </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created sample cases file: data\\sample_cases.xlsx\n"
          ]
        }
      ],
      "source": [
        "#Mock-up Dataset: the production can implement file upload from .xlsx or .csv / API connection with EHS.\n",
        "\n",
        "sample_cases = [\n",
        "    {\n",
        "        \"doi\": \"DOI_001\",\n",
        "        \"description\": \"45-year-old male presents with acute chest pain radiating to left arm, diaphoresis, and nausea. Pain started 2 hours ago during physical activity. Patient has history of hypertension and smoking. Vital signs: BP 160/90, HR 110, RR 20. ECG shows ST elevation in leads II, III, aVF.\",\n",
        "        \"ground_truth\": [\"Acute myocardial infarction\", \"Unstable angina\", \"Aortic dissection\"]\n",
        "    },\n",
        "    {\n",
        "        \"doi\": \"DOI_002\", \n",
        "        \"description\": \"28-year-old female with 3-day history of fever (39°C), headache, neck stiffness, and photophobia. No recent travel. Physical exam reveals positive Kernig's sign. CSF analysis shows elevated WBC count with neutrophil predominance, low glucose, high protein.\",\n",
        "        \"ground_truth\": [\"Bacterial meningitis\", \"Viral meningitis\", \"Subarachnoid hemorrhage\"]\n",
        "    },\n",
        "    {\n",
        "        \"doi\": \"DOI_003\",\n",
        "        \"description\": \"65-year-old diabetic patient presents with polyuria, polydipsia, weight loss, and blurred vision over 2 weeks. Random glucose 450 mg/dL, ketones positive in urine. Patient appears dehydrated with fruity breath odor.\",\n",
        "        \"ground_truth\": [\"Diabetic ketoacidosis\", \"Hyperosmolar hyperglycemic state\", \"Type 1 diabetes onset\"]\n",
        "    },\n",
        "    {\n",
        "        \"doi\": \"DOI_004\",\n",
        "        \"description\": \"32-year-old pregnant woman at 20 weeks gestation presents with sudden onset severe abdominal pain and vaginal bleeding. Pain is cramping in nature. Vital signs stable. Pelvic exam shows open cervix with tissue passage.\",\n",
        "        \"ground_truth\": [\"Incomplete abortion\", \"Inevitable abortion\", \"Placental abruption\"]\n",
        "    },\n",
        "    {\n",
        "        \"doi\": \"DOI_005\",\n",
        "        \"description\": \"8-year-old child with 2-day history of high fever, sore throat, and difficulty swallowing. Physical exam reveals enlarged, erythematous tonsils with white exudate, tender cervical lymphadenopathy, and petechiae on soft palate.\",\n",
        "        \"ground_truth\": [\"Streptococcal pharyngitis\", \"Viral pharyngitis\", \"Infectious mononucleosis\"]\n",
        "    }\n",
        "]\n",
        "df_cases = pd.DataFrame(sample_cases)\n",
        "df_cases.to_excel(config.CASES_FILE, index=False)\n",
        "print(f\"Created sample cases file: {config.CASES_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Processing</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "INITIALIZING MEDICAL DIAGNOSIS MODELS\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"INITIALIZING MEDICAL DIAGNOSIS MODELS\")\n",
        "print(\"=\" * 60)\n",
        "diagnosis_models = MedicalDiagnosisModels(config, rag_system)\n",
        "\n",
        "def process_all_cases(cases_df, models, output_file=None):\n",
        "    \"\"\"\n",
        "    Process all cases efficiently by running all cases through one model first,\n",
        "    then all cases through the second model. This avoids expensive model switching.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    print(\"Phase 1: Processing all cases with RAG-Enhanced Model\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Load RAG model once\n",
        "    models.load_rag_model()\n",
        "    \n",
        "    # Process all cases with RAG model\n",
        "    for idx, row in cases_df.iterrows():\n",
        "        case_id = row['doi']\n",
        "        description = row['description']\n",
        "        \n",
        "        print(f\"Processing {case_id} with RAG model...\")\n",
        "        \n",
        "        rag_result = models.generate_rag_diagnosis(description)\n",
        "        \n",
        "        result = {\n",
        "            'doi': case_id,\n",
        "            'description': description,\n",
        "            'ground_truth': row.get('ground_truth', []),\n",
        "            'rag_diagnosis': rag_result['diagnosis'],\n",
        "            'rag_sources': rag_result['sources'],\n",
        "            'bio_diagnosis': None,  # Will be filled later\n",
        "            'bio_sources': None\n",
        "        }\n",
        "        \n",
        "        results.append(result)\n",
        "        print(f\"DONE: {case_id} RAG processing complete\")\n",
        "    \n",
        "    # Clean up RAG model to free memory\n",
        "    print(\"\\nCleaning up RAG model...\")\n",
        "    models.rag_pipeline = None\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "    \n",
        "    print(\"\\nPhase 2: Processing all cases with Bio-Specialized Model\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Load Bio model\n",
        "    models.load_bio_model()\n",
        "    \n",
        "    # Process all cases with Bio model\n",
        "    for idx, result in enumerate(results):\n",
        "        case_id = result['doi']\n",
        "        description = result['description']\n",
        "        \n",
        "        print(f\"Processing {case_id} with Bio model...\")\n",
        "        \n",
        "        bio_result = models.generate_bio_diagnosis(description)\n",
        "        \n",
        "        result['bio_diagnosis'] = bio_result['diagnosis']\n",
        "        result['bio_sources'] = bio_result['sources']\n",
        "        \n",
        "        print(f\"DONE: {case_id} Bio processing complete\")\n",
        "    \n",
        "    # Save results\n",
        "    if output_file:\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_excel(output_file, index=False)\n",
        "        print(f\"\\nResults saved to: {output_file}\")\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 5 cases for processing\n"
          ]
        }
      ],
      "source": [
        "# Load sample cases\n",
        "cases_df = pd.read_excel(config.CASES_FILE)\n",
        "print(f\"Loaded {len(cases_df)} cases for processing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 1: Processing all cases with RAG-Enhanced Model\n",
            "============================================================\n",
            "Loading RAG model: microsoft/DialoGPT-medium\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG model loaded successfully!\n",
            "Processing DOI_001 with RAG model...\n",
            "DONE: DOI_001 RAG processing complete\n",
            "Processing DOI_002 with RAG model...\n",
            "DONE: DOI_002 RAG processing complete\n",
            "Processing DOI_003 with RAG model...\n",
            "DONE: DOI_003 RAG processing complete\n",
            "Processing DOI_004 with RAG model...\n",
            "DONE: DOI_004 RAG processing complete\n",
            "Processing DOI_005 with RAG model...\n",
            "DONE: DOI_005 RAG processing complete\n",
            "\n",
            "Cleaning up RAG model...\n",
            "\n",
            "Phase 2: Processing all cases with Bio-Specialized Model\n",
            "============================================================\n",
            "Loading Bio model: dmis-lab/biobert-base-cased-v1.1\n",
            "Using mock Bio model for demonstration...\n",
            "Processing DOI_001 with Bio model...\n",
            "DONE: DOI_001 Bio processing complete\n",
            "Processing DOI_002 with Bio model...\n",
            "DONE: DOI_002 Bio processing complete\n",
            "Processing DOI_003 with Bio model...\n",
            "DONE: DOI_003 Bio processing complete\n",
            "Processing DOI_004 with Bio model...\n",
            "DONE: DOI_004 Bio processing complete\n",
            "Processing DOI_005 with Bio model...\n",
            "DONE: DOI_005 Bio processing complete\n",
            "\n",
            "Results saved to: data\\results\\diagnosis_comparison_results.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Process all cases\n",
        "output_file = config.RESULTS_DIR / \"diagnosis_comparison_results.xlsx\"\n",
        "results = process_all_cases(cases_df, diagnosis_models, output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Result</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VpnZ57j8jEzI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "DIAGNOSIS COMPARISON RESULTS\n",
            "================================================================================\n",
            "DOI 1: DOI_001\n",
            "----------------------------------------\n",
            "Description: 45-year-old male presents with acute chest pain radiating to left arm, diaphoresis, and nausea. Pain...\n",
            "Ground Truth: ['Acute myocardial infarction', 'Unstable angina', 'Aortic dissection']\n",
            "\n",
            "RAG-Enhanced Model:\n",
            "Sources: ['fallback_sample', 'fallback_sample', 'fallback_sample']\n",
            "Diagnosis: ...\n",
            "\n",
            "Bio-Specialized Model:\n",
            "Sources: ['Bio-specialized training data']\n",
            "Diagnosis: Bio-specialized analysis:\n",
            "1. Acute myocardial infarction\n",
            "2. Unstable angina\n",
            "3. Aortic dissection\n",
            "4. Pulmonary embolism\n",
            "5. Pneumothorax\n",
            "6. Pericarditis\n",
            "7. Esophageal disorders\n",
            "8. Musculoskeletal pain\n",
            "9...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DOI 2: DOI_002\n",
            "----------------------------------------\n",
            "Description: 28-year-old female with 3-day history of fever (39°C), headache, neck stiffness, and photophobia. No...\n",
            "Ground Truth: ['Bacterial meningitis', 'Viral meningitis', 'Subarachnoid hemorrhage']\n",
            "\n",
            "RAG-Enhanced Model:\n",
            "Sources: ['fallback_sample', 'fallback_sample', 'fallback_sample']\n",
            "Diagnosis: ...\n",
            "\n",
            "Bio-Specialized Model:\n",
            "Sources: ['Bio-specialized training data']\n",
            "Diagnosis: Bio-specialized differential:\n",
            "1. Bacterial meningitis\n",
            "2. Viral meningitis\n",
            "3. Encephalitis\n",
            "4. Subarachnoid hemorrhage\n",
            "5. Brain tumor\n",
            "6. Migraine\n",
            "7. Cluster headache\n",
            "8. Sinusitis\n",
            "9. Hypertensive emergen...\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DIAGNOSIS COMPARISON RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, result in enumerate(results[:2]):  # Show first 2 results\n",
        "    print(f\"DOI {i+1}: {result['doi']}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Description: {result['description'][:100]}...\")\n",
        "    print(f\"Ground Truth: {result['ground_truth']}\")\n",
        "    \n",
        "    print(f\"\\nRAG-Enhanced Model:\")\n",
        "    print(f\"Sources: {result['rag_sources']}\")\n",
        "    print(f\"Diagnosis: {result['rag_diagnosis'][:200]}...\")\n",
        "    \n",
        "    print(f\"\\nBio-Specialized Model:\")\n",
        "    print(f\"Sources: {result['bio_sources']}\")\n",
        "    print(f\"Diagnosis: {result['bio_diagnosis'][:200]}...\")\n",
        "    print(\"\\n\" + \"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
